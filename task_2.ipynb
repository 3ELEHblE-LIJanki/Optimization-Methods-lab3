{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "добавили параметр regular (regular=regularity(коэффициент, L1_ratio - [0, 1])) \\\n",
    "regularity_L1(k) = regularity(k, 1) \\\n",
    "regularity_L2(k) = regularity(k, 0) \\\n",
    "\\\n",
    "Теперь общая функция потерь с регуляризацией:\n",
    "Lost(w) = MSE + λ*R(w)\n",
    "\n",
    "Так как само значение фцнкции потери нас не интересует..."
   ],
   "id": "f3ccc551b50012a2"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-28T01:46:22.643569Z",
     "start_time": "2025-05-28T01:46:19.847106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, \"./Optimization-lib\")\n",
    "from lrs import regularity, regularity_L1, regularity_L2\n",
    "from lrs import *\n",
    "from gradient_descent import GradientDecent, ScipyWrapper\n",
    "from newton import NewtonCG\n",
    "from function_wrapper import FunctionWrapper\n",
    "from output import *\n",
    "from graphics_plotter import GraphicsPlotter\n",
    "from stochastic_gradient_descent import StochGradientDecent\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "wine_quality = fetch_ucirepo(id=186)\n",
    "\n",
    "X = wine_quality.data.features  # Признаки\n",
    "y = wine_quality.data.targets\n",
    "\n",
    "X = X.values\n",
    "y = y.values.ravel()\n",
    "\n",
    "def normalize(X_train):\n",
    "    mean = X_train.mean(axis=0)  # Среднее по каждому признаку\n",
    "    std = X_train.std(axis=0)     # Стандартное отклонение по каждому признаку\n",
    "    std[std == 0] = 1            # Избегаем деления на 0 (если std=0)\n",
    "\n",
    "    # Нормализуем тренировочные и тестовые данные\n",
    "    X_train = (X_train - mean) / std\n",
    "\n",
    "    return X_train\n",
    "\n",
    "X = normalize(X)\n",
    "\n",
    "def generate_weight_bounds(X, abs_bound: int) -> list:\n",
    "    \"\"\"\n",
    "    Генерирует границы весов для всех параметров модели (включая intercept)\n",
    "    n_features: Количество признаков (без учёта const)\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    return [[-1 * abs_bound, abs_bound] for _ in range(n_features + 1)]  # +1 для intercept\n",
    "\n",
    "def generate_start(X) -> list:\n",
    "    n_features = X.shape[1]\n",
    "    return [0 for _ in range(n_features + 1)]  # +1 для intercept\n",
    "\n",
    "\n",
    "bounds = generate_weight_bounds(X, 100)\n",
    "start = generate_start(X)\n",
    "\n",
    "gradient.clear()\n",
    "sgd_reg = StochGradientDecent(exponential_decay(0.01, 0.0001), generate_weight_bounds(X, 1000), X, y, 5, regular=regularity(0.3, 0.1))\n",
    "error_min = sgd_reg.find_min(generate_start(X), 100)\n",
    "print(error_min)\n",
    "\n",
    "pretty_dataset_print(sgd_reg, \"EXP1_Elastic\", error_min, gradient)\n",
    "\n",
    "########################################################################\n",
    "gradient.clear()\n",
    "sgd_reg1 = StochGradientDecent(exponential_decay(0.01, 0.0001), generate_weight_bounds(X, 1000), X, y, 5, regular=regularity(0.3, 1))\n",
    "error_min = sgd_reg1.find_min(generate_start(X), 100)\n",
    "print(error_min)\n",
    "\n",
    "pretty_dataset_print(sgd_reg1, \"EXP1_L1\", error_min, gradient)\n",
    "# ///////////////////\n",
    "gradient.clear()\n",
    "sgd_reg2 = StochGradientDecent(exponential_decay(0.01, 0.0001), generate_weight_bounds(X, 1000), X, y, 5, regular=regularity(0.3, 0))\n",
    "error_min = sgd_reg2.find_min(generate_start(X), 100)\n",
    "print(error_min)\n",
    "\n",
    "pretty_dataset_print(sgd_reg2, \"EXP1_L2\", error_min, gradient)\n",
    "\n",
    "# //////////////////\n",
    "\n",
    "gradient.clear()\n",
    "sgd_reg2 = StochGradientDecent(exponential_decay(0.01, 0.0001), generate_weight_bounds(X, 1000), X, y, 5)\n",
    "error_min = sgd_reg2.find_min(generate_start(X), 100)\n",
    "print(error_min)\n",
    "\n",
    "pretty_dataset_print(sgd_reg2, \"EXP1\", error_min, gradient)\n",
    "\n",
    "\n",
    "# добавить график изменения значения error_min от количества итераций (?)\n",
    "\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0443274741130426\n",
      "\n",
      "        EXP1_Elastic\n",
      "            found min error:         2.044327\n",
      "            found weights:      ['4.59802859445133993432', '0.06396208665769237411', '-0.09582976040951582397', '0.10811976980054437136', '-0.00000887720498273176', '-0.10256167755774635297', '0.04664854464121247213', '-0.11011585915681075531', '-0.16166270699392801258', '0.06331957178803453157', '0.01498152827888841847', '0.21727093960578089393']\n",
      "            steps count:          100\n",
      "            function calls count: 1\n",
      "            gradient calls count: 0\n",
      "            hessian calls count:  0\n",
      "          \n",
      "1.388573184681534\n",
      "\n",
      "        EXP1_L1\n",
      "            found min error:         1.388573\n",
      "            found weights:      ['4.93687961385378315526', '-0.03255199752345819958', '-0.01959960705578680032', '-0.01268134939325121779', '0.01266507151546472990', '-0.00940920082817437754', '0.02407780770432473016', '-0.00230892965803266258', '-0.04010361470659500049', '-0.02346269933139020700', '-0.00811317220577187012', '0.14095636681444431715']\n",
      "            steps count:          100\n",
      "            function calls count: 1\n",
      "            gradient calls count: 0\n",
      "            hessian calls count:  0\n",
      "          \n",
      "2.2291433160319056\n",
      "\n",
      "        EXP1_L2\n",
      "            found min error:         2.229143\n",
      "            found weights:      ['4.54519088490335221309', '-0.10544362425017633766', '-0.09457895568000672382', '-0.05063325555399613570', '-0.00853293284110972529', '0.04961983147657627463', '0.09447474262246095822', '-0.06208925177169721116', '-0.29143747043868123425', '-0.01144677599484467817', '-0.01818641579716743020', '0.37975763342440177484']\n",
      "            steps count:          100\n",
      "            function calls count: 1\n",
      "            gradient calls count: 0\n",
      "            hessian calls count:  0\n",
      "          \n",
      "1.277957128859267\n",
      "\n",
      "        EXP1\n",
      "            found min error:         1.277957\n",
      "            found weights:      ['4.98043032006491248609', '0.00794020645374317845', '-0.11307327514250095635', '-0.02694068429974352807', '0.09791801842927168320', '-0.04436687577966572094', '0.06914365127107247044', '-0.10180530761626627179', '-0.08312500116058631205', '0.11452647356333239825', '0.02863124934932283205', '0.28084261787952785605']\n",
      "            steps count:          100\n",
      "            function calls count: 1\n",
      "            gradient calls count: 0\n",
      "            hessian calls count:  0\n",
      "          \n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:46:22.664786Z",
     "start_time": "2025-05-28T01:46:22.660209Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f259f422e95b6b93",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
